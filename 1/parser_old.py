import requests
from bs4 import BeautifulSoup
import csv
import json
import xml.etree.ElementTree as ET
from typing import List, Dict
import time
from urllib.parse import urljoin, urlparse


class RisbarParser:
    def __init__(self, base_url: str = "https://risbar.kz"):
        """
        –ü–∞—Ä—Å–µ—Ä –¥–ª—è —Å–∞–π—Ç–∞ risbar.kz
        :param base_url: –ë–∞–∑–æ–≤—ã–π URL —Å–∞–π—Ç–∞
        """
        self.base_url = base_url
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ru-RU,ru;q=0.9,en;q=0.8',
        })
        self.products = []

    def fetch_page(self, url: str) -> BeautifulSoup:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        :param url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        :return: BeautifulSoup –æ–±—ä–µ–∫—Ç
        """
        try:
            print(f"–ó–∞–≥—Ä—É–∑–∫–∞: {url}")
            response = self.session.get(url, timeout=15)
            response.raise_for_status()
            # time.sleep(1)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            return BeautifulSoup(response.content, 'lxml')
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {e}")
            return None

    def parse_product(self, product_url: str) -> Dict:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ç–æ–≤–∞—Ä–∞
        :param product_url: URL —Ç–æ–≤–∞—Ä–∞
        :return: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ —Ç–æ–≤–∞—Ä–∞
        """
        soup = self.fetch_page(product_url)
        if not soup:
            return None

        product = {
            'url': product_url,
            'title': '',
            'description': '',
            'details': '',
            'category': '',
            'article': '',
            'availability': '',
            'images': [],
            'price': ''
        }

        try:
            # –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ (–æ—Å–Ω–æ–≤–Ω–æ–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ)
            title_selectors = ['h1.product_title', 'h1', '.product_title']
            for selector in title_selectors:
                title_elem = soup.select_one(selector)
                if title_elem:
                    product['title'] = title_elem.get_text(strip=True)
                    break

            # –ê—Ä—Ç–∏–∫—É–ª - –∏—â–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ "–ê—Ä—Ç–∏–∫—É–ª"
            article_block = soup.find(text=lambda t: t and '–ê—Ä—Ç–∏–∫—É–ª' in t)
            if article_block:
                parent = article_block.find_parent()
                if parent:
                    article_text = parent.get_text(strip=True)
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—Ä—Ç–∏–∫—É–ª –ø–æ—Å–ª–µ –¥–≤–æ–µ—Ç–æ—á–∏—è
                    if ':' in article_text:
                        product['article'] = article_text.split(':', 1)[
                            1].strip()

            # –ö–∞—Ç–µ–≥–æ—Ä–∏—è - –∏—â–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ "–ö–∞—Ç–µ–≥–æ—Ä–∏—è"
            category_block = soup.find(text=lambda t: t and '–ö–∞—Ç–µ–≥–æ—Ä–∏—è' in t)
            if category_block:
                parent = category_block.find_parent()
                if parent:
                    # –ò—â–µ–º —Å–ª–µ–¥—É—é—â–∏–π —ç–ª–µ–º–µ–Ω—Ç —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–µ–π
                    next_elem = parent.find_next_sibling()
                    if next_elem:
                        product['category'] = next_elem.get_text(strip=True)

            # –ù–∞–ª–∏—á–∏–µ —Ç–æ–≤–∞—Ä–∞
            availability_elem = soup.select_one(
                '.stock, .availability, button:contains("–í –Ω–∞–ª–∏—á–∏–∏")')
            if availability_elem:
                product['availability'] = availability_elem.get_text(
                    strip=True)

            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–∞–ª–∏—á–∏—è
            if not product['availability']:
                avail_text = soup.find(
                    text=lambda t: t and '–Ω–∞–ª–∏—á–∏' in t.lower())
                if avail_text:
                    product['availability'] = avail_text.strip()

            # –û–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ (–≤–∫–ª–∞–¥–∫–∞ "–û–ü–ò–°–ê–ù–ò–ï")
            desc_elem = soup.select_one('#tab-description')
            if desc_elem:
                # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
                desc_text = desc_elem.get_text(separator=' ', strip=True)
                product['description'] = ' '.join(desc_text.split())

            # –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (–≤–∫–ª–∞–¥–∫–∞ "–•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò")
            # –ü–∞—Ä—Å–∏–º —Ç–∞–±–ª–∏—Ü—É —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏
            details_table = soup.select_one(
                '#tab-additional_information table.woocommerce-product-attributes')
            if details_table:
                characteristics = []
                rows = details_table.select('tr')
                for row in rows:
                    label = row.select_one(
                        '.woocommerce-product-attributes-item__label')
                    value = row.select_one(
                        '.woocommerce-product-attributes-item__value')
                    if label and value:
                        char_name = label.get_text(strip=True).replace(':', '')
                        char_value = value.get_text(strip=True)
                        characteristics.append(f"{char_name}: {char_value}")

                product['details'] = ' | '.join(characteristics)

            # –¶–µ–Ω–∞ (—É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º 0, —Ç–∞–∫ –∫–∞–∫ –Ω–∞ —Å–∞–π—Ç–µ —Å–∫—Ä—ã—Ç–∞)
            product['price'] = '0'

            # –ö–∞—Ä—Ç–∏–Ω–∫–∏ - –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤
            # 1. –û—Å–Ω–æ–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            main_img = soup.select_one(
                '.woocommerce-product-gallery__image img, .product-image img')
            if main_img:
                img_url = main_img.get('src') or main_img.get('data-src')
                if img_url:
                    product['images'].append(urljoin(self.base_url, img_url))

            # 2. –ú–∏–Ω–∏–∞—Ç—é—Ä—ã –≥–∞–ª–µ—Ä–µ–∏ –∏–∑ data-thumb
            gallery_thumbs = soup.select('div[data-thumb]')
            for thumb in gallery_thumbs:
                thumb_url = thumb.get('data-thumb')
                if thumb_url:
                    # –ó–∞–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –º–∏–Ω–∏–∞—Ç—é—Ä—ã –Ω–∞ –ø–æ–ª–Ω—ã–π —Ä–∞–∑–º–µ—Ä
                    full_url = thumb_url.replace(
                        '-100x100', '').replace('-150x150', '')
                    full_url = urljoin(self.base_url, full_url)
                    if full_url not in product['images']:
                        product['images'].append(full_url)

            # 3. –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –≥–∞–ª–µ—Ä–µ–µ
            gallery_images = soup.select(
                '.woocommerce-product-gallery__image img, .product-gallery img')
            for img in gallery_images:
                img_url = img.get('src') or img.get(
                    'data-src') or img.get('data-large_image')
                if img_url:
                    full_url = urljoin(self.base_url, img_url)
                    if full_url not in product['images']:
                        product['images'].append(full_url)

            print(f"‚úÖ –°–ø–∞—Ä—Å–µ–Ω: {product['title'][:50]}...")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–æ–≤–∞—Ä–∞ {product_url}: {e}")

        return product

    def get_pagination_urls(self, catalog_url: str) -> List[str]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö URL —Å—Ç—Ä–∞–Ω–∏—Ü –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
        :param catalog_url: URL –∫–∞—Ç–∞–ª–æ–≥–∞
        :return: –°–ø–∏—Å–æ–∫ URL –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
        """
        soup = self.fetch_page(catalog_url)
        if not soup:
            return [catalog_url]

        urls = [catalog_url]

        # –ò—â–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
        page_links = soup.select('.page-numbers')
        for link in page_links:
            href = link.get('href')
            if href and href not in urls:
                full_url = urljoin(self.base_url, href)
                urls.append(full_url)

        print(f"üìÑ –ù–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü –∫–∞—Ç–∞–ª–æ–≥–∞: {len(urls)}")
        return urls

    def parse_catalog(self, catalog_url: str = "https://risbar.kz/catalog/",
                      max_products: int = None,
                      use_pagination: bool = True) -> List[Dict]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ç–∞–ª–æ–≥–∞ —Ç–æ–≤–∞—Ä–æ–≤
        :param catalog_url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–∞—Ç–∞–ª–æ–≥–∞
        :param max_products: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤ (–¥–ª—è —Ç–µ—Å—Ç–∞)
        :param use_pagination: –ü–∞—Ä—Å–∏—Ç—å –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–∞—Ç–∞–ª–æ–≥–∞
        :return: –°–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤
        """
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–∞—Ç–∞–ª–æ–≥–∞
        if use_pagination:
            catalog_pages = self.get_pagination_urls(catalog_url)
        else:
            catalog_pages = [catalog_url]

        count = 0

        for page_url in catalog_pages:
            if max_products and count >= max_products:
                break

            soup = self.fetch_page(page_url)
            if not soup:
                continue

            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤
            # –°–µ–ª–µ–∫—Ç–æ—Ä: .product_wrap —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Å—ã–ª–∫—É a.db
            product_cards = soup.select('.product a.db')
            print(f"üîç –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(product_cards)}")

            for card in product_cards:
                if max_products and count >= max_products:
                    break

                product_url = card.get('href')
                if product_url:
                    full_url = urljoin(self.base_url, product_url)

                    product = self.parse_product(full_url)
                    if product and product.get('title'):
                        self.products.append(product)
                        count += 1
                        print(f"üì¶ –¢–æ–≤–∞—Ä–æ–≤ —Å–æ–±—Ä–∞–Ω–æ: {count}")

        return self.products

    def save_to_csv(self, filename: str = 'risbar_products.csv'):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ CSV"""
        if not self.products:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return

        with open(filename, 'w', newline='', encoding='utf-8-sig') as f:
            fieldnames = ['title', 'article', 'category', 'price', 'availability',
                          'description', 'details', 'images', 'url']
            writer = csv.DictWriter(f, fieldnames=fieldnames)

            writer.writeheader()
            for product in self.products:
                row = product.copy()
                row['images'] = '; '.join(product['images'])
                writer.writerow(row)

        print(f"‚úÖ CSV —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")

    def save_to_json(self, filename: str = 'risbar_products.json'):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON"""
        if not self.products:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.products, f, ensure_ascii=False, indent=2)

        print(f"‚úÖ JSON —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")

    def save_to_xml(self, filename: str = 'risbar_products.xml'):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ XML"""
        if not self.products:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return

        root = ET.Element('products')
        root.set('total', str(len(self.products)))

        for product in self.products:
            product_elem = ET.SubElement(root, 'product')

            for key, value in product.items():
                if key == 'images':
                    images_elem = ET.SubElement(product_elem, 'images')
                    for img_url in value:
                        img_elem = ET.SubElement(images_elem, 'image')
                        img_elem.text = img_url
                else:
                    elem = ET.SubElement(product_elem, key)
                    elem.text = str(value)

        tree = ET.ElementTree(root)
        ET.indent(tree, space="  ")
        tree.write(filename, encoding='utf-8', xml_declaration=True)

        print(f"‚úÖ XML —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")

    def save_all_formats(self, base_filename: str = 'risbar_products'):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–æ –≤—Å–µ—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ"""
        self.save_to_csv(f'{base_filename}.csv')
        self.save_to_json(f'{base_filename}.json')
        self.save_to_xml(f'{base_filename}.xml')


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä
    parser = RisbarParser()

    # –í–∞—Ä–∏–∞–Ω—Ç 1: –ü–∞—Ä—Å–∏–Ω–≥ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–¥–ª—è —Ç–µ—Å—Ç–∞)
    print("=" * 60)
    print("üöÄ –ó–ê–ü–£–°–ö –ü–ê–†–°–ï–†–ê RISBAR.KZ")
    print("=" * 60)

    # –ü–∞—Ä—Å–∏–º –∫–∞—Ç–∞–ª–æ–≥ (–ø–µ—Ä–≤—ã–µ 5 —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∞)
    # parser.parse_catalog(
    #     catalog_url="https://risbar.kz/catalog/",
    #     max_products=5,  # –î–ª—è —Ç–µ—Å—Ç–∞ –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ 5 —Ç–æ–≤–∞—Ä–æ–≤
    #     use_pagination=False  # –ù–µ –ø–∞—Ä—Å–∏–º –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã, —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é
    # )

    # # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    # parser.save_all_formats('risbar_products')

    # –í–∞—Ä–∏–∞–Ω—Ç 2: –ü–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ–≥–æ –∫–∞—Ç–∞–ª–æ–≥–∞ (—Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞)

    parser.parse_catalog(
        catalog_url="https://risbar.kz/catalog/",
        use_pagination=True  # –ü–∞—Ä—Å–∏–º –í–°–ï —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–∞—Ç–∞–ª–æ–≥–∞
    )

    print("=" * 60)
    print(f"‚úÖ –ì–û–¢–û–í–û! –í—Å–µ–≥–æ —Å–ø–∞—Ä—Å–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(parser.products)}")
    print("=" * 60)

    parser.save_all_formats('risbar_full_catalog')

    # –í–∞—Ä–∏–∞–Ω—Ç 3: –ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    """
    parser.parse_catalog(
        catalog_url="https://risbar.kz/product_cat/naushniki/",  # –ó–∞–º–µ–Ω–∏ –Ω–∞ –Ω—É–∂–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
        use_pagination=True
    )
    parser.save_all_formats('risbar_category')
    """
